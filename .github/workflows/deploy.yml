# Deploy Pipeline - Deploys to staging/production based on branch
# Uses AWS OIDC for secure, keyless authentication
#
# Workflow:
#   push to staging → deploy to staging environment
#   push to main    → deploy to production environment
#
# PERFORMANCE: Lambda deploys run in parallel after layer is published
# This reduces deploy time from ~7min to ~3-4min

name: Deploy

on:
  push:
    branches: [main, staging]
    paths-ignore:
      - '**.md'
      - 'docs/**'
      - '.github/dependabot.yml'
      - 'LICENSE'
      - '.gitignore'
  workflow_dispatch:
    inputs:
      force_full_deploy:
        description: 'Force full deploy (rebuild all components)'
        required: false
        type: boolean
        default: false
      wait_for_cdn:
        description: 'Wait for CloudFront invalidation to complete'
        required: false
        type: boolean
        default: true

# Only one deployment at a time per environment
concurrency:
  group: deploy-${{ github.ref_name }}
  cancel-in-progress: false

env:
  AWS_REGION: us-west-2
  PYTHON_VERSION: "3.11"
  NODE_VERSION: "20"
  # Auto-generated version: YYYY.MM.DD-<short-sha>
  APP_VERSION: ""  # Set dynamically in generate-version job

# Required for AWS OIDC authentication, release tagging, and drift issues
permissions:
  id-token: write
  contents: write  # Required for creating release tags
  issues: write    # Required for creating/updating drift issues

jobs:
  # ============================================
  # CI Checks (must pass before deploy)
  # ============================================

  ci:
    name: CI Checks
    uses: ./.github/workflows/ci.yml

  # ============================================
  # Detect Changed Components
  # ============================================

  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    # No needs - runs in parallel with CI for faster startup
    outputs:
      backend: ${{ steps.filter.outputs.backend }}
      frontend: ${{ steps.filter.outputs.frontend }}
      scraper: ${{ steps.filter.outputs.scraper }}
      image_processor: ${{ steps.filter.outputs.image_processor }}
      retry_queue_failed: ${{ steps.filter.outputs.retry_queue_failed }}
    steps:
      - uses: actions/checkout@v6

      - name: Detect changed paths
        uses: dorny/paths-filter@v3
        id: filter
        with:
          filters: |
            backend:
              - 'backend/**'
              - 'poetry.lock'
              - 'pyproject.toml'
              - 'requirements.txt'
            frontend:
              - 'frontend/**'
              - 'package.json'
              - 'package-lock.json'
            scraper:
              - 'scraper/**'
              - 'backend/app/scraper/**'
            image_processor:
              - 'backend/lambdas/image_processor/**'
              - 'backend/app/models/**'
            retry_queue_failed:
              - 'backend/lambdas/retry_queue_failed/**'

  # ============================================
  # Environment Configuration
  # ============================================

  configure:
    name: Configure Environment
    runs-on: ubuntu-latest
    outputs:
      environment: ${{ steps.env.outputs.environment }}
      drift_detected: ${{ steps.drift.outputs.drift_detected }}
      aws_account_id: ${{ steps.config.outputs.aws_account_id }}
      lambda_function_name: ${{ steps.config.outputs.lambda_function_name }}
      worker_function_name: ${{ steps.config.outputs.worker_function_name }}
      eval_runbook_worker_function_name: ${{ steps.config.outputs.eval_runbook_worker_function_name }}
      cleanup_function_name: ${{ steps.config.outputs.cleanup_function_name }}
      retry_queue_failed_function_name: ${{ steps.config.outputs.retry_queue_failed_function_name }}
      tracking_dispatcher_function_name: ${{ steps.config.outputs.tracking_dispatcher_function_name }}
      tracking_worker_function_name: ${{ steps.config.outputs.tracking_worker_function_name }}
      scraper_function_name: ${{ steps.config.outputs.scraper_function_name }}
      scraper_ecr_repository: ${{ steps.config.outputs.scraper_ecr_repository }}
      image_processor_function_name: ${{ steps.config.outputs.image_processor_function_name }}
      image_processor_ecr_repository: ${{ steps.config.outputs.image_processor_ecr_repository }}
      s3_frontend_bucket: ${{ steps.config.outputs.s3_frontend_bucket }}
      s3_artifacts_bucket: ${{ steps.config.outputs.s3_artifacts_bucket }}
      cloudfront_distribution_id: ${{ steps.config.outputs.cloudfront_distribution_id }}
      api_url: ${{ steps.config.outputs.api_url }}
      app_url: ${{ steps.config.outputs.app_url }}
      cognito_user_pool_id: ${{ steps.config.outputs.cognito_user_pool_id }}
      cognito_client_id: ${{ steps.config.outputs.cognito_client_id }}
      cognito_domain: ${{ steps.config.outputs.cognito_domain }}
    steps:
      - uses: actions/checkout@v6
        with:
          sparse-checkout: |
            infra/terraform
            infra/config
          sparse-checkout-cone-mode: false

      - name: Determine environment
        id: env
        run: |
          if [[ "${{ github.ref_name }}" == "main" ]]; then
            echo "environment=production" >> $GITHUB_OUTPUT
            echo "tf_backend_file=backends/prod.hcl" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref_name }}" == "staging" ]]; then
            echo "environment=staging" >> $GITHUB_OUTPUT
            echo "tf_backend_file=backends/staging.hcl" >> $GITHUB_OUTPUT
          else
            echo "ERROR: Unknown branch ${{ github.ref_name }}"
            exit 1
          fi

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ steps.env.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Get API key from Secrets Manager
        id: api-key
        run: |
          if [[ "${{ steps.env.outputs.environment }}" == "production" ]]; then
            SECRET_NAME="bluemoxon-prod/api-key"
          else
            SECRET_NAME="bluemoxon-staging/api-key"
          fi
          echo "Fetching API key from: $SECRET_NAME"
          API_KEY=$(aws secretsmanager get-secret-value --secret-id "$SECRET_NAME" --query 'SecretString' --output text)
          echo "::add-mask::$API_KEY"
          echo "api_key=$API_KEY" >> $GITHUB_OUTPUT

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false

      - name: Initialize Terraform
        working-directory: infra/terraform
        run: |
          # Use backend config files as single source of truth (DRY)
          terraform init -backend-config="${{ steps.env.outputs.tf_backend_file }}"

      # Drift check is non-blocking - warns but doesn't fail deployment
      - name: Check for infrastructure drift
        id: drift
        continue-on-error: true
        working-directory: infra/terraform
        env:
          TF_VAR_db_password: "drift-check-dummy-not-applied"
          TF_VAR_api_key: ${{ steps.api-key.outputs.api_key }}
        run: |
          echo "Running pre-deploy drift check..."
          ENV="${{ steps.env.outputs.environment }}"
          TFVARS_FILE="envs/${{ steps.env.outputs.environment == 'production' && 'prod' || 'staging' }}.tfvars"

          set +e
          set -o pipefail
          terraform plan -detailed-exitcode -var-file="$TFVARS_FILE" -no-color 2>&1 | tee plan-output.txt
          EXIT_CODE=${PIPESTATUS[0]}
          set -e

          if [ $EXIT_CODE -eq 0 ]; then
            echo "No infrastructure drift detected"
            echo "drift_detected=false" >> $GITHUB_OUTPUT
          elif [ $EXIT_CODE -eq 2 ]; then
            ADDS=$(grep -c "will be created" plan-output.txt 2>/dev/null || true)
            CHANGES=$(grep -c "will be updated" plan-output.txt 2>/dev/null || true)
            DESTROYS=$(grep -c "will be destroyed" plan-output.txt 2>/dev/null || true)
            ADDS="${ADDS:-0}"
            CHANGES="${CHANGES:-0}"
            DESTROYS="${DESTROYS:-0}"

            echo "::warning::Infrastructure drift detected in $ENV: +$ADDS ~$CHANGES -$DESTROYS resources"
            echo "drift_detected=true" >> $GITHUB_OUTPUT
            echo "adds=$ADDS" >> $GITHUB_OUTPUT
            echo "changes=$CHANGES" >> $GITHUB_OUTPUT
            echo "destroys=$DESTROYS" >> $GITHUB_OUTPUT
          else
            echo "::warning::Terraform plan failed (exit code $EXIT_CODE) - continuing deployment"
            echo "drift_detected=error" >> $GITHUB_OUTPUT
          fi

          rm -f plan-output.txt

      - name: Create or update drift issue
        if: steps.drift.outputs.drift_detected == 'true'
        uses: actions/github-script@v8
        env:
          DEPLOY_ENV: ${{ steps.env.outputs.environment }}
          DRIFT_ADDS: ${{ steps.drift.outputs.adds }}
          DRIFT_CHANGES: ${{ steps.drift.outputs.changes }}
          DRIFT_DESTROYS: ${{ steps.drift.outputs.destroys }}
          COMMIT_SHA: ${{ github.sha }}
          COMMIT_MSG: ${{ github.event.head_commit.message }}
          BRANCH_NAME: ${{ github.ref_name }}
        with:
          script: |
            const env = process.env.DEPLOY_ENV;
            const adds = process.env.DRIFT_ADDS || '0';
            const changes = process.env.DRIFT_CHANGES || '0';
            const destroys = process.env.DRIFT_DESTROYS || '0';
            const runUrl = `${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`;
            const commitSha = process.env.COMMIT_SHA;
            const commitMsg = (process.env.COMMIT_MSG || '').split('\n')[0];
            const branch = process.env.BRANCH_NAME;

            const existingIssues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'drift,infra',
              per_page: 10
            });

            const existingDriftIssue = existingIssues.data.find(
              issue => issue.title.includes(`[${env}]`) && issue.title.includes('Infrastructure Drift')
            );

            if (existingDriftIssue) {
              // Update existing issue with new detection
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingDriftIssue.number,
                body: `## Drift Still Present - Pre-Deploy Check

            **Detected during:** Deploy to ${env}
            **Branch:** \`${branch}\`
            **Commit:** [\`${commitSha.substring(0, 7)}\`](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/commit/${commitSha}) - ${commitMsg}
            **Date:** ${new Date().toISOString().split('T')[0]}

            | Metric | Count |
            |--------|-------|
            | Resources to add | ${adds} |
            | Resources to change | ${changes} |
            | Resources to destroy | ${destroys} |

            [View workflow run](${runUrl})

            ---
            WARNING: Deployment continued (warn-only mode)`
              });
              console.log(`Updated existing drift issue #${existingDriftIssue.number}`);
            } else {
              // Create new issue
              const issue = await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `[${env}] Infrastructure Drift Detected (Pre-Deploy)`,
                labels: ['drift', 'infra', 'priority:high'],
                body: `## Infrastructure Drift Detected During Deployment

            **Environment:** ${env}
            **Detected:** ${new Date().toISOString()}
            **Branch:** \`${branch}\`
            **Commit:** [\`${commitSha.substring(0, 7)}\`](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/commit/${commitSha}) - ${commitMsg}

            ### Summary
            | Metric | Count |
            |--------|-------|
            | Resources to add | ${adds} |
            | Resources to change | ${changes} |
            | Resources to destroy | ${destroys} |

            ### What Happened
            Pre-deploy drift check detected infrastructure differences. Deployment continued in **warn-only mode**.

            ### Next Steps
            1. Review the [workflow run](${runUrl}) for details
            2. Either:
               - Apply Terraform to fix drift: \`terraform apply -var-file=envs/${env === 'production' ? 'prod' : 'staging'}.tfvars\`
               - Import manual resources: \`terraform import\`
               - Document exception in \`docs/MANUAL_CHANGES.md\`

            ### Root Cause Investigation
            - [ ] Was this a manual AWS console change?
            - [ ] Was this a CLI change without Terraform?
            - [ ] Is this expected (pending Terraform PR)?

            ---
            Related: #235 (Pre-deploy drift check feature)`
              });
              console.log(`Created drift issue #${issue.data.number}`);
            }

      - name: Read Terraform outputs
        id: config
        working-directory: infra/terraform
        run: |
          echo "Reading configuration from Terraform state..."

          echo "environment=$(terraform output -raw environment)" >> $GITHUB_OUTPUT
          echo "aws_account_id=$(terraform output -raw aws_account_id)" >> $GITHUB_OUTPUT

          echo "lambda_function_name=$(terraform output -raw lambda_function_name)" >> $GITHUB_OUTPUT
          echo "worker_function_name=$(terraform output -raw analysis_worker_function_name)" >> $GITHUB_OUTPUT
          echo "eval_runbook_worker_function_name=$(terraform output -raw eval_runbook_worker_function_name)" >> $GITHUB_OUTPUT

          echo "cleanup_function_name=$(terraform output -raw cleanup_lambda_function_name 2>/dev/null || echo '')" >> $GITHUB_OUTPUT
          echo "retry_queue_failed_function_name=$(terraform output -raw retry_queue_failed_function_name 2>/dev/null || echo '')" >> $GITHUB_OUTPUT
          echo "tracking_dispatcher_function_name=$(terraform output -raw tracking_dispatcher_function_name 2>/dev/null || echo '')" >> $GITHUB_OUTPUT
          echo "tracking_worker_function_name=$(terraform output -raw tracking_worker_function_name 2>/dev/null || echo '')" >> $GITHUB_OUTPUT

          echo "scraper_function_name=$(terraform output -raw scraper_function_name 2>/dev/null || echo '')" >> $GITHUB_OUTPUT
          echo "scraper_ecr_repository=$(terraform output -raw scraper_ecr_repository 2>/dev/null || echo '')" >> $GITHUB_OUTPUT

          echo "image_processor_function_name=$(terraform output -raw image_processor_function_name 2>/dev/null || echo '')" >> $GITHUB_OUTPUT
          echo "image_processor_ecr_repository=$(terraform output -raw image_processor_ecr_url 2>/dev/null || echo '')" >> $GITHUB_OUTPUT

          echo "s3_frontend_bucket=$(terraform output -raw frontend_bucket_name)" >> $GITHUB_OUTPUT
          echo "s3_artifacts_bucket=$(terraform output -raw artifacts_bucket_name)" >> $GITHUB_OUTPUT
          echo "cloudfront_distribution_id=$(terraform output -raw frontend_cdn_distribution_id)" >> $GITHUB_OUTPUT

          echo "api_url=$(terraform output -raw api_url)" >> $GITHUB_OUTPUT
          echo "app_url=$(terraform output -raw app_url)" >> $GITHUB_OUTPUT

          echo "cognito_user_pool_id=$(terraform output -raw cognito_user_pool_id)" >> $GITHUB_OUTPUT
          echo "cognito_client_id=$(terraform output -raw cognito_client_id)" >> $GITHUB_OUTPUT
          echo "cognito_domain=$(terraform output -raw cognito_domain)" >> $GITHUB_OUTPUT

      - name: Validate config consistency
        working-directory: infra/terraform
        run: |
          # Compare against static config files (warn only, don't fail)
          if [[ "${{ steps.env.outputs.environment }}" == "production" ]]; then
            CONFIG_FILE="../config/production.json"
          else
            CONFIG_FILE="../config/staging.json"
          fi

          echo "Validating against static config: $CONFIG_FILE"

          # Compare key values
          STATIC_POOL_ID=$(jq -r '.cognito.user_pool_id' $CONFIG_FILE 2>/dev/null || echo '')
          TF_POOL_ID="${{ steps.config.outputs.cognito_user_pool_id }}"

          if [[ -n "$STATIC_POOL_ID" && "$STATIC_POOL_ID" != "$TF_POOL_ID" ]]; then
            echo "::warning::Config drift detected: cognito_user_pool_id"
            echo "  Static: $STATIC_POOL_ID"
            echo "  Terraform: $TF_POOL_ID"
          fi

          STATIC_CLIENT_ID=$(jq -r '.cognito.app_client_id' $CONFIG_FILE 2>/dev/null || echo '')
          TF_CLIENT_ID="${{ steps.config.outputs.cognito_client_id }}"

          if [[ -n "$STATIC_CLIENT_ID" && "$STATIC_CLIENT_ID" != "$TF_CLIENT_ID" ]]; then
            echo "::warning::Config drift detected: cognito_client_id"
            echo "  Static: $STATIC_CLIENT_ID"
            echo "  Terraform: $TF_CLIENT_ID"
          fi

          STATIC_LAMBDA=$(jq -r '.lambda.function_name' $CONFIG_FILE 2>/dev/null || echo '')
          TF_LAMBDA="${{ steps.config.outputs.lambda_function_name }}"

          if [[ -n "$STATIC_LAMBDA" && "$STATIC_LAMBDA" != "$TF_LAMBDA" ]]; then
            echo "::warning::Config drift detected: lambda_function_name"
            echo "  Static: $STATIC_LAMBDA"
            echo "  Terraform: $TF_LAMBDA"
          fi

          echo "Validation complete - using Terraform values as source of truth"

      - name: Validate artifacts bucket access
        run: |
          BUCKET="${{ steps.config.outputs.s3_artifacts_bucket }}"
          if [[ -z "$BUCKET" ]]; then
            echo "::error::artifacts_bucket_name not found in Terraform outputs"
            exit 1
          fi
          echo "Validating access to artifacts bucket: $BUCKET"
          if ! aws s3 ls "s3://${BUCKET}/" > /dev/null 2>&1; then
            echo "::error::Cannot access artifacts bucket: $BUCKET"
            echo "Verify bucket exists and deploy role has s3:ListBucket permission"
            exit 1
          fi
          echo "Artifacts bucket validation passed"

  # ============================================
  # Generate Version
  # ============================================

  generate-version:
    name: Generate Version
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.version.outputs.version }}
      short_sha: ${{ steps.version.outputs.short_sha }}
      deployed_at: ${{ steps.version.outputs.deployed_at }}
    steps:
      - name: Generate version string
        id: version
        run: |
          DATE=$(date -u +%Y.%m.%d)
          SHORT_SHA=${GITHUB_SHA::7}
          VERSION="${DATE}-${SHORT_SHA}"
          DEPLOYED_AT=$(date -u +%Y-%m-%dT%H:%M:%SZ)

          echo "Generated version: $VERSION"
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "short_sha=$SHORT_SHA" >> $GITHUB_OUTPUT
          echo "deployed_at=$DEPLOYED_AT" >> $GITHUB_OUTPUT

  # ============================================
  # Pre-flight Config Validation
  # ============================================
  # Validates that all required BMX_* settings from config.py
  # exist in Terraform Lambda environment variables.
  # Blocks deployment if required vars are missing.

  validate-config:
    name: Validate Lambda Config
    runs-on: ubuntu-latest
    needs: [configure, changes]
    if: needs.changes.outputs.backend == 'true' || github.event.inputs.force_full_deploy == 'true'

    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Extract expected env vars from config.py
        run: |
          python scripts/extract_config_vars.py backend/app/config.py > expected_vars.json
          echo "Expected vars:"
          cat expected_vars.json

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: us-west-2

      - name: Get actual Lambda env vars from AWS
        id: actual
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.lambda_function_name }}"
          echo "Getting env vars for Lambda: $FUNCTION_NAME"

          if aws lambda get-function --function-name "$FUNCTION_NAME" > /dev/null 2>&1; then
            aws lambda get-function-configuration --function-name "$FUNCTION_NAME" --query 'Environment.Variables' --output json > actual_vars.json
            echo "lambda_exists=true" >> $GITHUB_OUTPUT
            echo "Actual vars from Lambda:"
            head -c 500 actual_vars.json
          else
            echo "::warning::Lambda function $FUNCTION_NAME does not exist yet (first deploy?)"
            echo "lambda_exists=false" >> $GITHUB_OUTPUT
            echo "{}" > actual_vars.json
          fi

      - name: Validate config
        run: |
          if [[ "${{ steps.actual.outputs.lambda_exists }}" == "false" ]]; then
            echo "::warning::Skipping validation - Lambda does not exist yet (first deploy)"
            echo "First deploy detected. Config validation will run on subsequent deploys."
            exit 0
          fi
          python scripts/validate_lambda_config.py --expected expected_vars.json --actual-file actual_vars.json

  # ============================================
  # Build Jobs (run in parallel)
  # ============================================

  build-layer:
    name: Build Lambda Layer
    runs-on: ubuntu-latest
    needs: [ci, configure, changes, validate-config]
    if: needs.changes.outputs.backend == 'true' || github.event.inputs.force_full_deploy == 'true'
    outputs:
      layer_s3_key: ${{ steps.layer-check.outputs.layer_s3_key }}
      layer_exists: ${{ steps.layer-check.outputs.exists }}

    steps:
      - uses: actions/checkout@v6

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: docker-${{ runner.os }}-lambda-python312-layer-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            docker-${{ runner.os }}-lambda-python312-layer-

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Check if layer needs rebuild
        id: layer-check
        run: |
          REQ_HASH=$(sha256sum backend/requirements.txt | cut -d' ' -f1 | head -c 16)
          echo "lock_hash=$REQ_HASH" >> $GITHUB_OUTPUT
          echo "layer_s3_key=lambda/layer-${REQ_HASH}.zip" >> $GITHUB_OUTPUT

          # Check if layer already exists in S3 (artifacts bucket)
          S3_BUCKET="${{ needs.configure.outputs.s3_artifacts_bucket }}"
          if aws s3 ls "s3://${S3_BUCKET}/lambda/layer-${REQ_HASH}.zip" 2>/dev/null; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "Layer already exists for hash: $REQ_HASH"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "Layer needs to be built for hash: $REQ_HASH"
          fi

      - name: Build layer with Docker
        if: steps.layer-check.outputs.exists == 'false'
        run: |
          docker run --rm \
            --entrypoint /bin/bash \
            -v ${{ github.workspace }}/backend:/app:ro \
            -v /tmp/layer-build:/output \
            --platform linux/amd64 \
            public.ecr.aws/lambda/python:3.12 \
            -c "mkdir -p /output/python && pip install -q -t /output/python -r /app/requirements.txt"

      - name: Create and upload layer zip
        if: steps.layer-check.outputs.exists == 'false'
        run: |
          cd /tmp/layer-build
          zip -q -r ${{ github.workspace }}/layer.zip python -x "*.pyc" -x "*__pycache__*"
          ls -lh ${{ github.workspace }}/layer.zip

          LOCK_HASH=${{ steps.layer-check.outputs.lock_hash }}
          S3_BUCKET="${{ needs.configure.outputs.s3_artifacts_bucket }}"

          aws s3 cp ${{ github.workspace }}/layer.zip "s3://${S3_BUCKET}/lambda/layer-${LOCK_HASH}.zip"
          aws s3 cp ${{ github.workspace }}/layer.zip "s3://${S3_BUCKET}/lambda/layer.zip"

  build-backend:
    name: Build Lambda Package
    runs-on: ubuntu-latest
    needs: [ci, configure, generate-version, changes, validate-config]
    if: needs.changes.outputs.backend == 'true' || github.event.inputs.force_full_deploy == 'true'

    steps:
      - uses: actions/checkout@v6

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: docker-${{ runner.os }}-lambda-python312-backend-${{ hashFiles('backend/requirements.txt') }}
          restore-keys: |
            docker-${{ runner.os }}-lambda-python312-backend-

      - name: Create VERSION and version_info.json files
        run: |
          echo "${{ needs.generate-version.outputs.version }}" > VERSION
          cat > version_info.json << EOF
          {
            "version": "${{ needs.generate-version.outputs.version }}",
            "git_sha": "${{ github.sha }}",
            "deployed_at": "${{ needs.generate-version.outputs.deployed_at }}"
          }
          EOF

      - name: Build Lambda package with Docker
        run: |
          docker run --rm \
            --entrypoint /bin/bash \
            -v ${{ github.workspace }}/backend:/app:ro \
            -v ${{ github.workspace }}/VERSION:/VERSION:ro \
            -v ${{ github.workspace }}/version_info.json:/version_info.json:ro \
            -v /tmp/lambda-deploy:/output \
            --platform linux/amd64 \
            public.ecr.aws/lambda/python:3.12 \
            -c "cp -r /app/app /output/ && cp -r /app/lambdas /output/ && cp /VERSION /output/ && cp /version_info.json /output/"

      - name: Create deployment zip
        run: |
          cd /tmp/lambda-deploy
          zip -q -r ${{ github.workspace }}/lambda-package.zip . -x "*.pyc" -x "*__pycache__*"
          ls -lh ${{ github.workspace }}/lambda-package.zip

      - name: Upload Lambda artifact
        uses: actions/upload-artifact@v6
        with:
          name: lambda-package
          path: lambda-package.zip
          retention-days: 1

  build-scraper:
    name: Build Scraper Image
    runs-on: ubuntu-latest
    needs: [ci, configure, generate-version, changes, validate-config]
    if: |
      needs.configure.outputs.scraper_function_name != '' &&
      (needs.changes.outputs.scraper == 'true' || github.event.inputs.force_full_deploy == 'true')

    steps:
      - uses: actions/checkout@v6

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push scraper image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ needs.configure.outputs.scraper_ecr_repository }}
          IMAGE_TAG: ${{ needs.generate-version.outputs.version }}
        working-directory: scraper
        run: |
          docker build \
            --build-arg VERSION=$IMAGE_TAG \
            --provenance=false \
            --sbom=false \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            .
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

  build-frontend:
    name: Build Frontend
    runs-on: ubuntu-latest
    needs: [ci, configure, generate-version, changes, validate-config]
    if: needs.changes.outputs.frontend == 'true' || github.event.inputs.force_full_deploy == 'true'

    steps:
      - uses: actions/checkout@v6

      - name: Create VERSION file
        run: echo "${{ needs.generate-version.outputs.version }}" > VERSION

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json

      - name: Install dependencies
        working-directory: frontend
        run: npm ci

      - name: Build for ${{ needs.configure.outputs.environment }}
        working-directory: frontend
        env:
          VITE_API_URL: ${{ needs.configure.outputs.api_url }}
          VITE_COGNITO_USER_POOL_ID: ${{ needs.configure.outputs.cognito_user_pool_id }}
          VITE_COGNITO_APP_CLIENT_ID: ${{ needs.configure.outputs.cognito_client_id }}
          VITE_COGNITO_DOMAIN: ${{ needs.configure.outputs.cognito_domain }}
        run: npm run build:validate

      - name: Upload frontend artifact
        uses: actions/upload-artifact@v6
        with:
          name: frontend-dist
          path: frontend/dist
          retention-days: 1
          overwrite: true

  # ============================================
  # Test Image Processor
  # ============================================

  test-image-processor:
    name: Test Image Processor
    runs-on: ubuntu-latest
    needs: [ci, changes]
    if: needs.changes.outputs.image_processor == 'true' || github.event.inputs.force_full_deploy == 'true'

    steps:
      - uses: actions/checkout@v6

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-image-processor-${{ hashFiles('backend/lambdas/image_processor/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-image-processor-

      - name: Install test dependencies
        run: |
          cd backend/lambdas/image_processor
          pip install -r requirements.txt pytest pytest-mock

      - name: Run tests
        run: |
          cd backend/lambdas/image_processor
          pytest tests/ -v

  # ============================================
  # Build Image Processor
  # ============================================

  build-image-processor:
    name: Build Image Processor
    runs-on: ubuntu-latest
    needs: [ci, configure, generate-version, changes, test-image-processor]
    if: |
      always() &&
      needs.test-image-processor.result == 'success' &&
      needs.configure.outputs.image_processor_function_name != '' &&
      (needs.changes.outputs.image_processor == 'true' || github.event.inputs.force_full_deploy == 'true')
    outputs:
      image_uri: ${{ steps.build.outputs.image_uri }}

    steps:
      - uses: actions/checkout@v6

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Build and push image
        id: build
        env:
          ECR_URL: ${{ needs.configure.outputs.image_processor_ecr_repository }}
          IMAGE_TAG: ${{ needs.generate-version.outputs.version }}
        run: |
          IMAGE_URI="${ECR_URL}:${IMAGE_TAG}"
          echo "Building image: $IMAGE_URI"

          docker build \
            --build-arg VERSION=$IMAGE_TAG \
            --provenance=false \
            --sbom=false \
            --platform linux/amd64 \
            -f backend/lambdas/image_processor/Dockerfile \
            -t $IMAGE_URI \
            .

          docker push $IMAGE_URI
          echo "image_uri=$IMAGE_URI" >> $GITHUB_OUTPUT

  # ============================================
  # Deploy API Lambda
  # ============================================
  # Condition pattern for deploy jobs:
  # - always(): Evaluate condition even if upstream jobs skipped
  # - result == 'success': REQUIRED - deploy needs build artifacts
  # - changes check: Only deploy if relevant files changed (or force deploy)

  deploy-api-lambda:
    name: Deploy API Lambda
    runs-on: ubuntu-latest
    needs: [configure, generate-version, build-layer, build-backend, changes]
    if: |
      always() &&
      needs.configure.result == 'success' &&
      needs.build-backend.result == 'success' &&
      needs.build-layer.result == 'success' &&
      (needs.changes.outputs.backend == 'true' || github.event.inputs.force_full_deploy == 'true')
    environment: ${{ needs.configure.outputs.environment }}
    outputs:
      version: ${{ steps.publish-version.outputs.version }}
      layer_arn: ${{ steps.publish-layer.outputs.layer_arn }}

    steps:
      - name: Download Lambda artifact
        uses: actions/download-artifact@v7
        with:
          name: lambda-package

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Upload Lambda to S3
        run: |
          aws s3 cp lambda-package.zip s3://${{ needs.configure.outputs.s3_artifacts_bucket }}/lambda/backend.zip

      - name: Publish or reuse layer version
        id: publish-layer
        run: |
          ENV="${{ needs.configure.outputs.environment }}"
          S3_BUCKET="${{ needs.configure.outputs.s3_artifacts_bucket }}"
          LAYER_S3_KEY="${{ needs.build-layer.outputs.layer_s3_key }}"
          LAYER_NAME="bluemoxon-${ENV}-deps"
          LAYER_EXISTS="${{ needs.build-layer.outputs.layer_exists }}"

          echo "Layer name: $LAYER_NAME"
          echo "S3 location: s3://${S3_BUCKET}/${LAYER_S3_KEY}"

          if [[ "$LAYER_EXISTS" == "true" ]]; then
            echo "Layer content unchanged, checking for existing layer version..."
            LATEST_VERSION_INFO=$(aws lambda list-layer-versions --layer-name "$LAYER_NAME" --max-items 1 --query 'LayerVersions[0]' --output json 2>/dev/null || echo "{}")

            if [[ "$LATEST_VERSION_INFO" != "{}" && "$LATEST_VERSION_INFO" != "null" ]]; then
              LATEST_VERSION_ARN=$(echo "$LATEST_VERSION_INFO" | jq -r '.LayerVersionArn')
              echo "Reusing existing layer version: $LATEST_VERSION_ARN"
              echo "layer_arn=$LATEST_VERSION_ARN" >> $GITHUB_OUTPUT
              exit 0
            fi
          fi

          echo "Publishing new layer version from s3://${S3_BUCKET}/${LAYER_S3_KEY}"
          LAYER_ARN=$(aws lambda publish-layer-version --layer-name "$LAYER_NAME" --description "Python dependencies for BlueMoxon Lambdas" --content S3Bucket=${S3_BUCKET},S3Key=${LAYER_S3_KEY} --compatible-runtimes python3.12 --query 'LayerVersionArn' --output text)

          echo "Published new layer: $LAYER_ARN"
          echo "layer_arn=$LAYER_ARN" >> $GITHUB_OUTPUT

      - name: Update Lambda with new layer
        run: |
          LAYER_ARN="${{ steps.publish-layer.outputs.layer_arn }}"
          echo "Updating Lambda with layer: $LAYER_ARN"
          aws lambda update-function-configuration --function-name ${{ needs.configure.outputs.lambda_function_name }} --layers "$LAYER_ARN"

      - name: Wait for config update
        run: |
          echo "Waiting for Lambda configuration update..."
          aws lambda wait function-updated --function-name ${{ needs.configure.outputs.lambda_function_name }}
          echo "Lambda function layer updated successfully"

      - name: Update Lambda code
        run: |
          aws lambda update-function-code --function-name ${{ needs.configure.outputs.lambda_function_name }} --s3-bucket ${{ needs.configure.outputs.s3_artifacts_bucket }} --s3-key lambda/backend.zip

      - name: Wait for code update
        run: |
          echo "Waiting for Lambda function to be ready..."
          aws lambda wait function-updated --function-name ${{ needs.configure.outputs.lambda_function_name }}
          echo "Lambda function code updated successfully"

      - name: Publish Lambda version
        id: publish-version
        run: |
          echo "Publishing new Lambda version..."
          VERSION=$(aws lambda publish-version --function-name ${{ needs.configure.outputs.lambda_function_name }} --description "Deployed from commit ${{ github.sha }}" --query 'Version' --output text)
          echo "Published version: $VERSION"
          echo "version=$VERSION" >> $GITHUB_OUTPUT

      - name: Update alias
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.lambda_function_name }}"
          VERSION="${{ steps.publish-version.outputs.version }}"
          if [[ "${{ needs.configure.outputs.environment }}" == "production" ]]; then
            ALIAS_NAME="prod"
          else
            ALIAS_NAME="staging"
          fi

          if aws lambda get-alias --function-name "$FUNCTION_NAME" --name "$ALIAS_NAME" 2>/dev/null; then
            echo "Updating existing alias '$ALIAS_NAME' to version $VERSION"
            aws lambda update-alias --function-name "$FUNCTION_NAME" --name "$ALIAS_NAME" --function-version "$VERSION"
          else
            echo "Creating alias '$ALIAS_NAME' pointing to version $VERSION"
            aws lambda create-alias --function-name "$FUNCTION_NAME" --name "$ALIAS_NAME" --function-version "$VERSION"
          fi

      - name: Cleanup old versions
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.lambda_function_name }}"
          KEEP_VERSIONS=3

          echo "Cleaning up old Lambda versions (keeping last $KEEP_VERSIONS)..."
          VERSIONS=$(aws lambda list-versions-by-function --function-name "$FUNCTION_NAME" --query 'Versions[?Version!=`$LATEST`].Version' --output text | tr '\t' '\n' | sort -rn)
          VERSIONS_TO_DELETE=$(echo "$VERSIONS" | tail -n +$((KEEP_VERSIONS + 1)))

          if [ -z "$VERSIONS_TO_DELETE" ]; then
            echo "No old versions to delete"
          else
            for VERSION in $VERSIONS_TO_DELETE; do
              echo "Deleting version $VERSION"
              aws lambda delete-function --function-name "$FUNCTION_NAME" --qualifier "$VERSION" || true
            done
          fi

  # ============================================
  # Deploy Worker Lambdas (Matrix)
  # ============================================

  deploy-worker-lambdas:
    name: Deploy ${{ matrix.display_name }} Lambda
    runs-on: ubuntu-latest
    needs: [configure, generate-version, build-layer, build-backend, changes, deploy-api-lambda]
    if: |
      always() &&
      needs.configure.result == 'success' &&
      needs.deploy-api-lambda.result == 'success' &&
      (needs.changes.outputs.backend == 'true' || github.event.inputs.force_full_deploy == 'true')
    environment: ${{ needs.configure.outputs.environment }}
    strategy:
      matrix:
        include:
          - name: worker
            display_name: Analysis Worker
          - name: eval-runbook-worker
            display_name: Eval Runbook Worker
          - name: cleanup
            display_name: Cleanup
          - name: retry-queue-failed
            display_name: Retry Queue Failed
          - name: tracking-dispatcher
            display_name: Tracking Dispatcher
          - name: tracking-worker
            display_name: Tracking Worker
      fail-fast: false

    steps:
      - name: Get function name
        id: get-fn
        run: |
          case "${{ matrix.name }}" in
            worker)
              FN="${{ needs.configure.outputs.worker_function_name }}"
              ;;
            eval-runbook-worker)
              FN="${{ needs.configure.outputs.eval_runbook_worker_function_name }}"
              ;;
            cleanup)
              FN="${{ needs.configure.outputs.cleanup_function_name }}"
              ;;
            retry-queue-failed)
              FN="${{ needs.configure.outputs.retry_queue_failed_function_name }}"
              ;;
            tracking-dispatcher)
              FN="${{ needs.configure.outputs.tracking_dispatcher_function_name }}"
              ;;
            tracking-worker)
              FN="${{ needs.configure.outputs.tracking_worker_function_name }}"
              ;;
          esac

          if [[ -z "$FN" ]]; then
            echo "skip=true" >> $GITHUB_OUTPUT
            echo "Lambda ${{ matrix.display_name }} not configured in this environment, skipping"
          else
            echo "skip=false" >> $GITHUB_OUTPUT
            echo "function_name=$FN" >> $GITHUB_OUTPUT
            echo "Deploying Lambda: $FN"
          fi

      - name: Configure AWS credentials via OIDC
        if: steps.get-fn.outputs.skip != 'true'
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: us-west-2

      - name: Update Lambda with layer
        if: steps.get-fn.outputs.skip != 'true'
        run: |
          LAYER_ARN="${{ needs.deploy-api-lambda.outputs.layer_arn }}"
          echo "Updating ${{ matrix.display_name }} Lambda with layer: $LAYER_ARN"
          aws lambda update-function-configuration \
            --function-name "${{ steps.get-fn.outputs.function_name }}" \
            --layers "$LAYER_ARN"

      - name: Wait for Lambda config update
        if: steps.get-fn.outputs.skip != 'true'
        run: |
          aws lambda wait function-updated \
            --function-name "${{ steps.get-fn.outputs.function_name }}"

      - name: Update Lambda function code
        if: steps.get-fn.outputs.skip != 'true'
        run: |
          echo "Deploying ${{ matrix.display_name }} Lambda code"
          aws lambda update-function-code \
            --function-name "${{ steps.get-fn.outputs.function_name }}" \
            --s3-bucket ${{ needs.configure.outputs.s3_artifacts_bucket }} \
            --s3-key lambda/backend.zip

      - name: Wait for Lambda code update
        if: steps.get-fn.outputs.skip != 'true'
        run: |
          aws lambda wait function-updated \
            --function-name "${{ steps.get-fn.outputs.function_name }}"

      - name: Publish Lambda version
        if: steps.get-fn.outputs.skip != 'true'
        id: publish-version
        run: |
          echo "Publishing new ${{ matrix.display_name }} Lambda version..."
          VERSION=$(aws lambda publish-version \
            --function-name "${{ steps.get-fn.outputs.function_name }}" \
            --description "Deployed from commit ${{ github.sha }}" \
            --query 'Version' \
            --output text)
          echo "Published version: $VERSION"
          echo "version=$VERSION" >> $GITHUB_OUTPUT

      - name: Cleanup old Lambda versions
        if: steps.get-fn.outputs.skip != 'true'
        run: |
          FUNCTION_NAME="${{ steps.get-fn.outputs.function_name }}"
          KEEP_VERSIONS=3
          echo "Cleaning up old ${{ matrix.display_name }} Lambda versions (keeping last $KEEP_VERSIONS)..."

          VERSIONS=$(aws lambda list-versions-by-function \
            --function-name "$FUNCTION_NAME" \
            --query 'Versions[?Version!=\`$LATEST\`].Version' \
            --output text | tr '\t' '\n' | sort -rn)
          VERSIONS_TO_DELETE=$(echo "$VERSIONS" | tail -n +$((KEEP_VERSIONS + 1)))

          if [ -z "$VERSIONS_TO_DELETE" ]; then
            echo "No old versions to delete"
          else
            for VERSION in $VERSIONS_TO_DELETE; do
              echo "Deleting version $VERSION"
              aws lambda delete-function --function-name "$FUNCTION_NAME" --qualifier "$VERSION" || true
            done
          fi
  # ============================================
  # Deploy Scraper Lambda
  # ============================================

  deploy-scraper-lambda:
    name: Deploy Scraper Lambda
    runs-on: ubuntu-latest
    needs: [configure, generate-version, build-scraper, changes]
    if: |
      always() &&
      needs.configure.result == 'success' &&
      needs.build-scraper.result == 'success' &&
      needs.configure.outputs.scraper_function_name != '' &&
      (needs.changes.outputs.scraper == 'true' || github.event.inputs.force_full_deploy == 'true')
    environment: ${{ needs.configure.outputs.environment }}
    outputs:
      version: ${{ steps.publish-version.outputs.version }}

    steps:
      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update Scraper Lambda function
        run: |
          SCRAPER_FUNCTION="${{ needs.configure.outputs.scraper_function_name }}"
          ECR_REPOSITORY="${{ needs.configure.outputs.scraper_ecr_repository }}"
          AWS_ACCOUNT="${{ needs.configure.outputs.aws_account_id }}"
          IMAGE_TAG="${{ needs.generate-version.outputs.version }}"
          IMAGE_URI="${AWS_ACCOUNT}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${ECR_REPOSITORY}:${IMAGE_TAG}"

          echo "Deploying scraper Lambda: $SCRAPER_FUNCTION"
          echo "Image URI: $IMAGE_URI"
          aws lambda update-function-code --function-name "$SCRAPER_FUNCTION" --image-uri "$IMAGE_URI"

      - name: Wait for Scraper Lambda update
        run: |
          aws lambda wait function-updated \
            --function-name ${{ needs.configure.outputs.scraper_function_name }}

      - name: Publish Scraper Lambda version
        id: publish-version
        run: |
          SCRAPER_FUNCTION="${{ needs.configure.outputs.scraper_function_name }}"
          echo "Publishing new Scraper Lambda version..."
          VERSION=$(aws lambda publish-version --function-name "$SCRAPER_FUNCTION" --description "Deployed from commit ${{ github.sha }}" --query 'Version' --output text)
          echo "Published scraper version: $VERSION"
          echo "version=$VERSION" >> $GITHUB_OUTPUT

      - name: Cleanup old Scraper Lambda versions
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.scraper_function_name }}"
          KEEP_VERSIONS=3
          echo "Cleaning up old Scraper Lambda versions (keeping last $KEEP_VERSIONS)..."
          VERSIONS=$(aws lambda list-versions-by-function --function-name "$FUNCTION_NAME" --query 'Versions[?Version!=`$LATEST`].Version' --output text | tr '\t' '\n' | sort -rn)
          VERSIONS_TO_DELETE=$(echo "$VERSIONS" | tail -n +$((KEEP_VERSIONS + 1)))
          if [ -z "$VERSIONS_TO_DELETE" ]; then
            echo "No old versions to delete"
          else
            for VERSION in $VERSIONS_TO_DELETE; do
              echo "Deleting version $VERSION"
              aws lambda delete-function --function-name "$FUNCTION_NAME" --qualifier "$VERSION" || true
            done
          fi

  # ============================================
  # Deploy Image Processor Lambda
  # ============================================

  deploy-image-processor-lambda:
    name: Deploy Image Processor Lambda
    runs-on: ubuntu-latest
    needs: [configure, generate-version, build-image-processor, changes]
    if: |
      always() &&
      needs.configure.result == 'success' &&
      needs.build-image-processor.result == 'success' &&
      needs.configure.outputs.image_processor_function_name != '' &&
      (needs.changes.outputs.image_processor == 'true' || github.event.inputs.force_full_deploy == 'true')
    environment: ${{ needs.configure.outputs.environment }}
    outputs:
      version: ${{ steps.publish-version.outputs.version }}

    steps:
      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update Image Processor Lambda function
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.image_processor_function_name }}"
          IMAGE_URI="${{ needs.build-image-processor.outputs.image_uri }}"

          echo "Deploying image processor Lambda: $FUNCTION_NAME"
          echo "Image URI: $IMAGE_URI"
          aws lambda update-function-code --function-name "$FUNCTION_NAME" --image-uri "$IMAGE_URI"

      - name: Wait for Lambda update
        run: |
          aws lambda wait function-updated \
            --function-name ${{ needs.configure.outputs.image_processor_function_name }}

      - name: Tag deployment
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.image_processor_function_name }}"
          aws lambda tag-resource \
            --resource arn:aws:lambda:${{ env.AWS_REGION }}:${{ needs.configure.outputs.aws_account_id }}:function:$FUNCTION_NAME \
            --tags DeployedCommit=${{ github.sha }},DeployedAt=$(date -u +%Y-%m-%dT%H:%M:%SZ)

      - name: Smoke test
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.image_processor_function_name }}"
          aws lambda invoke \
            --function-name "$FUNCTION_NAME" \
            --payload '{"smoke_test": true}' \
            --cli-binary-format raw-in-base64-out \
            /tmp/response.json

          cat /tmp/response.json

          if grep -q "errorMessage" /tmp/response.json; then
            echo "Smoke test failed"
            exit 1
          fi

          echo "Smoke test passed"

      - name: Publish Lambda version
        id: publish-version
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.image_processor_function_name }}"
          VERSION=$(aws lambda publish-version --function-name "$FUNCTION_NAME" --description "Deployed from commit ${{ github.sha }}" --query 'Version' --output text)
          echo "Published version: $VERSION"
          echo "version=$VERSION" >> $GITHUB_OUTPUT

      - name: Cleanup old versions
        run: |
          FUNCTION_NAME="${{ needs.configure.outputs.image_processor_function_name }}"
          KEEP_VERSIONS=3
          echo "Cleaning up old versions (keeping last $KEEP_VERSIONS)..."
          VERSIONS=$(aws lambda list-versions-by-function --function-name "$FUNCTION_NAME" --query 'Versions[?Version!=`$LATEST`].Version' --output text | tr '\t' '\n' | sort -rn)
          VERSIONS_TO_DELETE=$(echo "$VERSIONS" | tail -n +$((KEEP_VERSIONS + 1)))
          if [ -z "$VERSIONS_TO_DELETE" ]; then
            echo "No old versions to delete"
          else
            for VERSION in $VERSIONS_TO_DELETE; do
              echo "Deleting version $VERSION"
              aws lambda delete-function --function-name "$FUNCTION_NAME" --qualifier "$VERSION" || true
            done
          fi

  # ============================================
  # Deploy Frontend
  # ============================================

  deploy-frontend:
    name: Deploy Frontend
    runs-on: ubuntu-latest
    needs: [configure, generate-version, build-frontend, changes]
    if: |
      always() &&
      needs.configure.result == 'success' &&
      needs.build-frontend.result == 'success' &&
      (needs.changes.outputs.frontend == 'true' || github.event.inputs.force_full_deploy == 'true')
    environment: ${{ needs.configure.outputs.environment }}

    steps:
      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download frontend artifact
        uses: actions/download-artifact@v7
        with:
          name: frontend-dist
          path: frontend-dist

      - name: Sync frontend to S3 (hashed assets)
        run: |
          echo "Syncing hashed assets with long cache..."
          aws s3 sync frontend-dist/ s3://${{ needs.configure.outputs.s3_frontend_bucket }}/ --delete --cache-control "max-age=31536000,public" --exclude "index.html" --exclude "*.json" --exclude "lambda/*"

      - name: Upload index.html with no-cache
        run: |
          echo "Uploading index.html with no-cache..."
          aws s3 cp frontend-dist/index.html s3://${{ needs.configure.outputs.s3_frontend_bucket }}/index.html --cache-control "no-cache,no-store,must-revalidate"

      - name: Upload JSON config files with no-cache
        run: |
          echo "Uploading JSON config files..."
          S3_BUCKET="${{ needs.configure.outputs.s3_frontend_bucket }}"
          if ls frontend-dist/*.json 1> /dev/null 2>&1; then
            for f in frontend-dist/*.json; do
              FILENAME=$(basename "$f")
              echo "Uploading $FILENAME"
              aws s3 cp "$f" "s3://${S3_BUCKET}/${FILENAME}" --cache-control "no-cache,no-store,must-revalidate"
            done
          else
            echo "No JSON config files to upload"
          fi

      - name: Create CloudFront invalidation
        id: invalidation
        run: |
          DISTRIBUTION_ID="${{ needs.configure.outputs.cloudfront_distribution_id }}"
          echo "Creating CloudFront invalidation..."
          INVALIDATION_ID=$(aws cloudfront create-invalidation --distribution-id "$DISTRIBUTION_ID" --paths "/*" --query 'Invalidation.Id' --output text)
          echo "CloudFront invalidation started: $INVALIDATION_ID"
          echo "invalidation_id=$INVALIDATION_ID" >> $GITHUB_OUTPUT

      - name: Wait for CloudFront invalidation
        if: github.event.inputs.wait_for_cdn != 'false'
        run: |
          DISTRIBUTION_ID="${{ needs.configure.outputs.cloudfront_distribution_id }}"
          INVALIDATION_ID="${{ steps.invalidation.outputs.invalidation_id }}"
          echo "Waiting for invalidation $INVALIDATION_ID to complete..."
          aws cloudfront wait invalidation-completed --distribution-id "$DISTRIBUTION_ID" --id "$INVALIDATION_ID"
          echo "CloudFront invalidation completed"

      - name: Skip CloudFront wait
        if: github.event.inputs.wait_for_cdn == 'false'
        run: |
          echo "Skipping CloudFront invalidation wait (wait_for_cdn=false)"
          echo "Invalidation ID: ${{ steps.invalidation.outputs.invalidation_id }}"
          echo "Note: Invalidation is still in progress, just not waiting for completion"

  # ============================================
  # Run Database Migrations
  # ============================================

  run-migrations:
    name: Run Database Migrations
    runs-on: ubuntu-latest
    needs: [configure, deploy-api-lambda, changes]
    if: |
      always() &&
      needs.deploy-api-lambda.result == 'success' &&
      (needs.changes.outputs.backend == 'true' || github.event.inputs.force_full_deploy == 'true')

    steps:
      - name: Verify API key secret exists
        env:
          BMX_API_KEY: ${{ needs.configure.outputs.environment == 'production' && secrets.BMX_API_KEY || secrets.BMX_STAGING_API_KEY }}
        run: |
          if [ -z "${BMX_API_KEY}" ]; then
            echo "::error::BMX_API_KEY secret is not set for ${{ needs.configure.outputs.environment }}"
            echo "Required secrets: BMX_API_KEY (production) or BMX_STAGING_API_KEY (staging)"
            exit 1
          fi
          echo "API key secret verified"

      - name: Wait for Lambda to be fully available
        run: sleep 5

      - name: Run database migrations
        env:
          BMX_API_KEY: ${{ needs.configure.outputs.environment == 'production' && secrets.BMX_API_KEY || secrets.BMX_STAGING_API_KEY }}
        run: |
          echo "Running database migrations..."
          API_URL="${{ needs.configure.outputs.api_url }}"

          response=$(curl -s -w "\n%{http_code}" -H "X-API-Key: ${BMX_API_KEY}" -X POST "${API_URL}/health/migrate")
          http_code=$(echo "$response" | tail -n1)
          body=$(echo "$response" | sed '$d')

          echo "HTTP Code: $http_code"
          echo "Response:"
          echo "$body" | jq '.' 2>/dev/null || echo "$body"

          if [[ "$http_code" != "200" ]]; then
            echo "ERROR: Migration endpoint returned HTTP $http_code"
            exit 1
          fi

          status=$(echo "$body" | jq -r '.status' 2>/dev/null)
          if [[ "$status" == "failed" ]]; then
            echo "ERROR: Migrations failed!"
            echo "$body" | jq '.errors' 2>/dev/null
            exit 1
          fi

          prev_version=$(echo "$body" | jq -r '.previous_version // "none"' 2>/dev/null)
          new_version=$(echo "$body" | jq -r '.new_version // "unknown"' 2>/dev/null)
          result_count=$(echo "$body" | jq -r '.results | length' 2>/dev/null)

          echo ""
          echo "Migrations completed successfully!"
          echo "   Previous version: $prev_version"
          echo "   New version: $new_version"
          echo "   Statements executed: $result_count"

  # ============================================
  # Smoke Tests (after all deploys complete)
  # ============================================
  # IMPORTANT: The `needs:` list and `if:` condition are intentionally different!
  #
  # needs: Lists ALL deploy jobs so smoke-test waits for everything to complete
  #
  # if: Only checks INDEPENDENT deploy jobs (API, scraper, frontend)
  #     Worker lambdas are omitted because they always deploy WITH the API lambda
  #     (same build artifacts, same change detection). If API succeeds, workers succeed.
  #
  # WHEN ADDING A NEW LAMBDA:
  # - If it deploys independently (own build/change detection): Add to BOTH needs AND if
  # - If it deploys with an existing lambda (shares artifacts): Add to needs ONLY

  smoke-test:
    name: Smoke Tests (${{ needs.configure.outputs.environment }})
    runs-on: ubuntu-latest
    needs:
      - configure
      - generate-version
      - changes
      - deploy-api-lambda
      - deploy-worker-lambdas
      - deploy-scraper-lambda
      - deploy-image-processor-lambda
      - deploy-frontend
      - run-migrations
    if: |
      always() &&
      !cancelled() &&
      (needs.deploy-api-lambda.result == 'success' ||
       needs.deploy-scraper-lambda.result == 'success' ||
       needs.deploy-image-processor-lambda.result == 'success' ||
       needs.deploy-frontend.result == 'success')

    steps:
      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ needs.configure.outputs.environment == 'production' && secrets.AWS_DEPLOY_ROLE_ARN || secrets.AWS_STAGING_ROLE_ARN }}
          aws-region: us-west-2

      - name: Wait for API readiness
        run: |
          echo "Polling API health endpoint..."
          API_URL="${{ needs.configure.outputs.api_url }}"
          for i in {1..10}; do
            if curl -sf "${API_URL}/api/v1/health" > /dev/null 2>&1; then
              echo "API ready after $((i * 3)) seconds"
              exit 0
            fi
            echo "Attempt $i/10: API not ready, waiting 3s..."
            sleep 3
          done
          echo "::warning::API did not respond within 30 seconds, proceeding with tests"

      - name: Set test URLs
        id: urls
        run: |
          ENV="${{ needs.configure.outputs.environment }}"
          if [[ "$ENV" == "production" ]]; then
            echo "api_base=https://api.bluemoxon.com" >> $GITHUB_OUTPUT
            echo "app_url=https://app.bluemoxon.com" >> $GITHUB_OUTPUT
          else
            echo "api_base=https://staging.api.bluemoxon.com" >> $GITHUB_OUTPUT
            echo "app_url=https://staging.app.bluemoxon.com" >> $GITHUB_OUTPUT
          fi

      - name: Check for partial deploy failures (atomicity)
        run: |
          echo "Checking for partial deploy failures..."
          FAILED_JOBS=""

          API_RESULT="${{ needs.deploy-api-lambda.result }}"
          WORKER_LAMBDAS_RESULT="${{ needs.deploy-worker-lambdas.result }}"
          SCRAPER_RESULT="${{ needs.deploy-scraper-lambda.result }}"
          IMAGE_PROCESSOR_RESULT="${{ needs.deploy-image-processor-lambda.result }}"
          FRONTEND_RESULT="${{ needs.deploy-frontend.result }}"

          echo "Deploy results:"
          echo "  API Lambda: $API_RESULT"
          echo "  Worker Lambdas (matrix): $WORKER_LAMBDAS_RESULT"
          echo "  Scraper Lambda: $SCRAPER_RESULT"
          echo "  Image Processor Lambda: $IMAGE_PROCESSOR_RESULT"
          echo "  Frontend: $FRONTEND_RESULT"

          # Check for any non-successful, non-skipped results (failure, cancelled, or unexpected)
          if [[ "$API_RESULT" != "success" && "$API_RESULT" != "skipped" ]]; then FAILED_JOBS="$FAILED_JOBS deploy-api-lambda($API_RESULT)"; fi
          if [[ "$WORKER_LAMBDAS_RESULT" != "success" && "$WORKER_LAMBDAS_RESULT" != "skipped" ]]; then FAILED_JOBS="$FAILED_JOBS deploy-worker-lambdas($WORKER_LAMBDAS_RESULT)"; fi
          if [[ "$SCRAPER_RESULT" != "success" && "$SCRAPER_RESULT" != "skipped" ]]; then FAILED_JOBS="$FAILED_JOBS deploy-scraper-lambda($SCRAPER_RESULT)"; fi
          if [[ "$IMAGE_PROCESSOR_RESULT" != "success" && "$IMAGE_PROCESSOR_RESULT" != "skipped" ]]; then FAILED_JOBS="$FAILED_JOBS deploy-image-processor-lambda($IMAGE_PROCESSOR_RESULT)"; fi
          if [[ "$FRONTEND_RESULT" != "success" && "$FRONTEND_RESULT" != "skipped" ]]; then FAILED_JOBS="$FAILED_JOBS deploy-frontend($FRONTEND_RESULT)"; fi

          if [[ -n "$FAILED_JOBS" ]]; then
            echo ""
            echo "CRITICAL: Partial deploy detected - some jobs did not succeed!"
            echo "Failed/cancelled jobs:$FAILED_JOBS"
            echo ""
            echo "This indicates an inconsistent deployment state."
            echo "Review the failed jobs and consider running force_full_deploy to restore consistency."
            exit 1
          fi

          echo "No partial failures detected"

      - name: Test API liveness
        run: |
          API_BASE="${{ steps.urls.outputs.api_base }}"
          response=$(curl -s -w "\n%{http_code}" "${API_BASE}/health")
          http_code=$(echo "$response" | tail -n1)

          if [[ "$http_code" != "200" ]]; then
            echo "Liveness check failed!"
            exit 1
          fi
          echo "API liveness check passed!"

      - name: Validate version and environment
        if: needs.deploy-api-lambda.result == 'success'
        run: |
          API_BASE="${{ steps.urls.outputs.api_base }}"
          EXPECTED_VERSION="${{ needs.generate-version.outputs.version }}"
          EXPECTED_ENV="${{ needs.configure.outputs.environment }}"

          response=$(curl -s "${API_BASE}/api/v1/health/version")
          ACTUAL_VERSION=$(echo "$response" | jq -r '.version')
          ACTUAL_ENV=$(echo "$response" | jq -r '.environment')

          if [[ "$ACTUAL_VERSION" != "$EXPECTED_VERSION" ]]; then
            echo "ERROR: Version mismatch! Expected: $EXPECTED_VERSION, Got: $ACTUAL_VERSION"
            exit 1
          fi

          if [[ "$ACTUAL_ENV" != "$EXPECTED_ENV" ]]; then
            echo "ERROR: Environment mismatch! Expected: $EXPECTED_ENV, Got: $ACTUAL_ENV"
            exit 1
          fi

          echo "Version and environment validation passed!"

      - name: Skip version check (no backend changes)
        if: needs.deploy-api-lambda.result == 'skipped'
        run: |
          echo "Skipping version check - no backend changes detected"
          echo "API Lambda deploy result: ${{ needs.deploy-api-lambda.result }}"

      - name: Handle API Lambda deploy failed
        if: needs.deploy-api-lambda.result == 'failure'
        run: |
          echo "API Lambda deployment failed - cannot validate version"
          exit 1

      - name: Handle API Lambda deploy cancelled
        if: needs.deploy-api-lambda.result == 'cancelled'
        run: |
          echo "::warning::API Lambda deployment was cancelled (user-initiated) - skipping version check"
          exit 0

      - name: Test API deep health check
        run: |
          API_BASE="${{ steps.urls.outputs.api_base }}"
          response=$(curl -s -w "\n%{http_code}" "${API_BASE}/api/v1/health/deep")
          http_code=$(echo "$response" | tail -n1)
          body=$(echo "$response" | sed '$d')

          if [[ "$http_code" != "200" ]]; then
            echo "Deep health check failed!"
            exit 1
          fi

          status=$(echo "$body" | jq -r '.status' 2>/dev/null)
          if [[ "$status" == "unhealthy" ]]; then
            echo "CRITICAL: System is unhealthy!"
            echo "$body" | jq '.checks' 2>/dev/null
            exit 1
          fi

          echo "Deep health check passed!"

      - name: Test API books endpoint
        env:
          BMX_API_KEY: ${{ needs.configure.outputs.environment == 'production' && secrets.BMX_API_KEY || secrets.BMX_STAGING_API_KEY }}
        run: |
          API_BASE="${{ steps.urls.outputs.api_base }}"
          response=$(curl -s -w "\n%{http_code}" -H "X-API-Key: ${BMX_API_KEY}" "${API_BASE}/api/v1/books?per_page=1")
          http_code=$(echo "$response" | tail -n1)

          if [[ "$http_code" != "200" ]]; then
            echo "Books API check failed!"
            exit 1
          fi
          echo "Books API check passed!"

      - name: Test Vue app loads
        run: |
          APP_URL="${{ steps.urls.outputs.app_url }}"
          http_code=$(curl -s -o /dev/null -w "%{http_code}" "$APP_URL")

          if [[ "$http_code" != "200" ]]; then
            echo "Vue app check failed!"
            exit 1
          fi
          echo "Vue app check passed!"

      - name: Validate frontend config
        if: needs.deploy-frontend.result == 'success'
        run: |
          APP_URL="${{ steps.urls.outputs.app_url }}"
          EXPECTED_VERSION="${{ needs.generate-version.outputs.version }}"
          EXPECTED_CLIENT_ID="${{ needs.configure.outputs.cognito_client_id }}"

          html=$(curl -s "$APP_URL")
          js_file=$(echo "$html" | grep -oE '/assets/index-[a-zA-Z0-9_-]+\.js' | head -1)

          if [[ -z "$js_file" ]]; then
            echo "ERROR: Could not find JS bundle!"
            exit 1
          fi

          js_content=$(curl -s "${APP_URL}${js_file}")

          if ! echo "$js_content" | grep -q "$EXPECTED_VERSION"; then
            echo "ERROR: Frontend version mismatch!"
            exit 1
          fi

          if ! echo "$js_content" | grep -q "$EXPECTED_CLIENT_ID"; then
            echo "ERROR: Cognito client ID mismatch!"
            exit 1
          fi

          echo "Frontend validation passed!"

      - name: Skip frontend config check (no frontend changes)
        if: needs.deploy-frontend.result == 'skipped'
        run: |
          echo "Skipping frontend config validation - no frontend changes detected"
          echo "Frontend deploy result: ${{ needs.deploy-frontend.result }}"

      - name: Handle frontend deploy failed
        if: needs.deploy-frontend.result == 'failure'
        run: |
          echo "Frontend deployment failed - cannot validate config"
          exit 1

      - name: Handle frontend deploy cancelled
        if: needs.deploy-frontend.result == 'cancelled'
        run: |
          echo "::warning::Frontend deployment was cancelled (user-initiated) - skipping config validation"
          exit 0

      - name: Test image endpoint
        env:
          BMX_API_KEY: ${{ needs.configure.outputs.environment == 'production' && secrets.BMX_API_KEY || secrets.BMX_STAGING_API_KEY }}
        run: |
          API_BASE="${{ steps.urls.outputs.api_base }}"
          ENV="${{ needs.configure.outputs.environment }}"

          book_response=$(curl -s -H "X-API-Key: ${BMX_API_KEY}" "${API_BASE}/api/v1/books?has_images=true&per_page=1")
          total_with_images=$(echo "$book_response" | jq -r '.total' 2>/dev/null)

          if [[ "$total_with_images" == "0" || "$total_with_images" == "null" ]]; then
            echo "INFO: No books with images found"
            exit 0
          fi

          if echo "$book_response" | grep -q '"primary_image_url"'; then
            image_url=$(echo "$book_response" | jq -r '.items[0].primary_image_url' 2>/dev/null)

            if [[ "$image_url" == /* ]]; then
              if [[ "$ENV" == "staging" ]]; then
                echo "INFO: Staging uses relative URLs - skipping CDN test"
                exit 0
              fi
              image_url="${API_BASE}${image_url}"
            fi

            if [[ -n "$image_url" && "$image_url" != "null" ]]; then
              response=$(curl -sI -L "$image_url")
              http_code=$(echo "$response" | grep -i "^HTTP" | tail -1 | awk '{print $2}')
              content_type=$(echo "$response" | grep -i "^content-type:" | tail -1 | awk '{print $2}' | tr -d '\r')

              if [[ "$http_code" != "200" ]]; then
                echo "ERROR: Image returned HTTP $http_code"
                exit 1
              fi

              if [[ ! "$content_type" =~ ^image/ ]]; then
                echo "ERROR: Image returned content-type '$content_type', expected image/*"
                exit 1
              fi

              echo "Image endpoint working!"
            fi
          fi

      - name: Test Scraper Lambda version
        if: needs.configure.outputs.scraper_function_name != '' && needs.deploy-scraper-lambda.result == 'success'
        run: |
          echo "Testing Scraper Lambda version..."
          SCRAPER_FUNCTION="${{ needs.configure.outputs.scraper_function_name }}"
          EXPECTED_VERSION="${{ needs.generate-version.outputs.version }}"

          # Invoke Lambda with version check payload
          response=$(aws lambda invoke \
            --function-name "$SCRAPER_FUNCTION" \
            --payload '{"version": true}' \
            --cli-binary-format raw-in-base64-out \
            /tmp/scraper-response.json \
            --query 'StatusCode' \
            --output text)

          echo "Lambda invoke status: $response"

          if [[ "$response" != "200" ]]; then
            echo "ERROR: Scraper Lambda invocation failed with status $response"
            exit 1
          fi

          # Parse response body
          body=$(cat /tmp/scraper-response.json)
          echo "Response body: $body"

          # Extract version from response
          actual_version=$(echo "$body" | jq -r '.body' | jq -r '.version')
          echo "Expected version: $EXPECTED_VERSION"
          echo "Actual version: $actual_version"

          if [[ "$actual_version" != "$EXPECTED_VERSION" ]]; then
            echo "ERROR: Scraper version mismatch!"
            echo "  Expected: $EXPECTED_VERSION"
            echo "  Got: $actual_version"
            exit 1
          fi

          echo "Scraper Lambda version check passed!"

      - name: Test Analysis Worker Lambda version
        if: needs.configure.outputs.worker_function_name != '' && needs.deploy-worker-lambdas.result == 'success'
        run: |
          WORKER_FUNCTION="${{ needs.configure.outputs.worker_function_name }}"
          EXPECTED_VERSION="${{ needs.generate-version.outputs.version }}"

          response=$(aws lambda invoke \
            --function-name "$WORKER_FUNCTION" \
            --payload '{"version": true}' \
            --cli-binary-format raw-in-base64-out \
            /tmp/worker-response.json \
            --query 'StatusCode' --output text)

          if [[ "$response" != "200" ]]; then
            echo "ERROR: Worker Lambda invocation failed"
            exit 1
          fi

          actual_version=$(cat /tmp/worker-response.json | jq -r '.body' | jq -r '.version')

          if [[ "$actual_version" != "$EXPECTED_VERSION" ]]; then
            echo "ERROR: Worker version mismatch! Expected: $EXPECTED_VERSION, Got: $actual_version"
            exit 1
          fi

          echo "Worker Lambda version check passed!"

      - name: Deployment summary
        run: |
          ENV="${{ needs.configure.outputs.environment }}"
          APP_URL="${{ steps.urls.outputs.app_url }}"
          API_BASE="${{ steps.urls.outputs.api_base }}"
          VERSION="${{ needs.generate-version.outputs.version }}"
          DRIFT_STATUS="${{ needs.configure.outputs.drift_detected }}"
          SCRAPER_FUNCTION="${{ needs.configure.outputs.scraper_function_name }}"
          WORKER_FUNCTION="${{ needs.configure.outputs.worker_function_name }}"
          EVAL_RUNBOOK_FUNCTION="${{ needs.configure.outputs.eval_runbook_worker_function_name }}"
          TRACKING_DISPATCHER_FUNCTION="${{ needs.configure.outputs.tracking_dispatcher_function_name }}"
          TRACKING_WORKER_FUNCTION="${{ needs.configure.outputs.tracking_worker_function_name }}"

          # Lambda published versions
          API_LAMBDA_VER="${{ needs.deploy-api-lambda.outputs.version }}"
          SCRAPER_LAMBDA_VER="${{ needs.deploy-scraper-lambda.outputs.version }}"
          # Worker lambdas deployed via matrix job (individual versions not exposed)

          echo "========================================"
          echo "Deployment to $ENV completed successfully!"
          echo "========================================"
          echo ""
          echo "App Version: $VERSION"
          echo "URLs:"
          echo "  App: $APP_URL"
          echo "  API: $API_BASE"
          echo ""
          echo "Lambda Versions:"
          echo "  API: v${{ needs.deploy-api-lambda.outputs.lambda_version }}"
          echo "  Worker: v${{ needs.deploy-workers.outputs.worker_version }}"
          echo "  Eval Worker: v${{ needs.deploy-workers.outputs.eval_worker_version }}"
          echo "========================================"

  # ============================================
  # Create Release Tag (production only)
  # ============================================

  create-release:
    name: Create Release Tag
    runs-on: ubuntu-latest
    needs: [configure, smoke-test]
    if: needs.configure.outputs.environment == 'production'

    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Create release tag
        run: |
          VERSION="v$(date -u '+%Y.%m.%d')-$(echo ${{ github.sha }} | head -c 7)"

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git tag -a "$VERSION" -m "Release $VERSION

          Deployed at: $(date -u '+%Y-%m-%d %H:%M:%S UTC')
          Commit: ${{ github.sha }}"

          git push origin "$VERSION"
          echo "Release tag created: $VERSION"
